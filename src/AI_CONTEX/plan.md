# DETAILED IMPLEMENTATION PLAN: AI Integration with @ Prefix
## Keeping Both AI Systems (cmd_ai.c + mysh_llm.py)

---

## ðŸŽ¯ **PROJECT GOAL**

Integrate the professor's mysh_llm.py AI system into your existing PicoBox shell while **keeping your current cmd_ai.c implementation**. Both systems will coexist:

- **cmd_ai.c**: Grammar-based `AI how do I...` syntax (legacy, cool feature)
- **mysh_llm.py**: Modern `@show me files` syntax (new, recommended approach)

**Key Constraint**: The `@` detection happens **BEFORE** BNFC parsing, so both systems are completely independent.

---

## ðŸ“‹ **PREREQUISITES CHECKLIST**

Before starting implementation:

- [ ] Read professor's mysh_llm.py code (provided document)
- [ ] Understand current cmd_ai.c implementation
- [ ] Confirm BNFC parser is working
- [ ] Have access to OpenAI API key (or plan to use fallback)
- [ ] Python 3.7+ installed
- [ ] Git repository for version control
- [ ] Backup of current working code

---

## ðŸ—ï¸ **ARCHITECTURE OVERVIEW**

```
USER INPUT
    â”‚
    â”œâ”€â”€â”€ Starts with @ â†’ SKIP BNFC â†’ mysh_llm.py (NEW)
    â”‚                                     â†“
    â”‚                              Suggestion â†’ User confirms â†’ BNFC parses
    â”‚
    â””â”€â”€â”€ Starts with "AI" â†’ BNFC parses â†’ cmd_ai.c (EXISTING)
                                              â†“
                                         Direct OpenAI call â†’ Answer
```

**Critical Insight**: The `@` check happens in the REPL loop **before** `psInput()` is called, so the grammar never sees `@` commands. Your `AICmd` grammar rule stays untouched.

---

## ðŸ“¦ **IMPLEMENTATION PHASES**

### **PHASE 1: Preparation & Environment Setup**
**Time Estimate**: 30 minutes

#### **1.1: Backup Current Code**
```bash
# Create backup branch
git checkout -b backup-before-ai-integration
git add -A
git commit -m "Backup before mysh_llm.py integration"
git checkout main

# Or manual backup
cp main.c main.c.backup
cp shell_bnfc.c shell_bnfc.c.backup
tar -czf backup-$(date +%Y%m%d).tar.gz *.c *.h
```

**Testing**: Verify backup exists and is complete.

#### **1.2: Set Up Python Environment**
```bash
# Check Python version (need 3.7+)
python3 --version

# Create virtual environment (optional but recommended)
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install openai  # For LLM calls
pip install jsonschema  # For validating JSON (optional)
```

**Testing**:
```bash
python3 -c "import openai; print('OpenAI installed')"
```

#### **1.3: Prepare Environment Variables**
```bash
# Create .env file (don't commit this!)
cat > .env << 'EOF'
# OpenAI API Key (get from platform.openai.com)
export OPENAI_API_KEY='sk-your-key-here'

# Path to picobox binary (for mysh_llm.py to call)
export MYSH_PATH='./picobox'
export MYSH_CATALOG_CMD='./picobox --commands-json'

# Optional: Enable debug output
# export MYSH_LLM_DEBUG=1

# Optional: Change model
# export MYSH_LLM_MODEL='gpt-4o-mini'
EOF

# Load environment
source .env
```

**Testing**:
```bash
echo $OPENAI_API_KEY  # Should print your key
echo $MYSH_PATH       # Should print ./picobox
```

#### **1.4: Understand Current Architecture**
Read and document your current code:

```bash
# Find where REPL loop is
grep -n "fgets.*stdin" shell_bnfc.c

# Find where BNFC parser is called
grep -n "psInput" shell_bnfc.c

# Find where AICmd is handled
grep -n "is_AICmd" shell_bnfc.c

# Document current flow
cat > CURRENT_ARCHITECTURE.md << 'EOF'
# Current REPL Flow
1. Print prompt
2. fgets() reads line
3. psInput() parses line
4. execute_command() dispatches:
   - is_SimpleCmd â†’ execute_single_simple_command()
   - is_PipeCmd â†’ execute_pipeline_command()
   - is_AICmd â†’ execute_ai_command()
5. Display result
EOF
```

**Testing**: Compile and run current code to ensure everything works.

---

### **PHASE 2: Add --commands-json to main.c**
**Time Estimate**: 1 hour (including testing)

This is the **foundation** of the RAG system. The shell must export its command catalog in JSON format.

#### **2.1: Add JSON Output Function**

**File**: `main.c`

**Location**: Before `print_usage()` function

**Implementation**:
```c
/*
 * Print all commands in JSON format for AI helper
 * 
 * This is called when: picobox --commands-json
 * 
 * Output format:
 * {
 *   "commands": [
 *     {
 *       "name": "echo",
 *       "summary": "print text to stdout",
 *       "description": "Echo the STRING(s) to standard output...",
 *       "usage": "echo [OPTION]... [STRING]...",
 *       "options": [
 *         {
 *           "short": "-n",
 *           "long": "--no-newline",
 *           "arg": null,
 *           "help": "do not output trailing newline"
 *         }
 *       ]
 *     },
 *     ...
 *   ]
 * }
 */
static void print_commands_json(void)
{
    int first = 1;
    
    printf("{\n");
    printf("  \"commands\": [\n");
    
    /* Iterate through command dispatch table */
    for (int i = 0; commands[i].name != NULL; i++) {
        /* Add comma before all but first command */
        if (!first) {
            printf(",\n");
        }
        first = 0;
        
        printf("    {\n");
        printf("      \"name\": \"%s\",\n", commands[i].name);
        
        /* Get command spec from registry for detailed info */
        const cmd_spec_t *spec = lookup_command(commands[i].name);
        
        if (spec) {
            /* Use detailed info from spec */
            printf("      \"summary\": \"%s\",\n", 
                   spec->summary ? spec->summary : "");
            
            /* Escape quotes in description */
            if (spec->long_help) {
                printf("      \"description\": \"");
                for (const char *p = spec->long_help; *p; p++) {
                    if (*p == '"' || *p == '\\') {
                        putchar('\\');
                    }
                    if (*p == '\n') {
                        printf("\\n");
                    } else {
                        putchar(*p);
                    }
                }
                printf("\",\n");
            } else {
                printf("      \"description\": \"\",\n");
            }
            
            /* Usage string */
            printf("      \"usage\": \"%s [OPTIONS]...\",\n", commands[i].name);
            
            /* Options array - TODO: extract from argtable3 */
            printf("      \"options\": []\n");
        } else {
            /* Fallback if no spec found */
            printf("      \"summary\": \"Unix utility\",\n");
            printf("      \"description\": \"See '%s --help' for details\",\n", 
                   commands[i].name);
            printf("      \"usage\": \"%s [OPTIONS]...\",\n", commands[i].name);
            printf("      \"options\": []\n");
        }
        
        printf("    }");
    }
    
    printf("\n  ]\n");
    printf("}\n");
}
```

**Detailed Explanation**:
- Walks the `commands[]` dispatch table
- For each command, looks up its `cmd_spec_t` in the registry
- Extracts name, summary, description from the spec
- Outputs valid JSON (proper escaping, comma handling)
- Options array is empty for now (Phase 3 enhancement)

**Common Pitfalls**:
1. **Forgetting commas**: JSON requires commas between array elements
2. **Forgetting to escape quotes**: Description strings may contain `"`
3. **Trailing comma**: Last element must NOT have a comma
4. **NULL pointers**: Check `spec->long_help` before using

#### **2.2: Add --commands-json Flag Handler**

**File**: `main.c`

**Location**: In `main()` function, after `init_commands()` call

**Implementation**:
```c
int main(int argc, char **argv)
{
    char *program_name;
    char *command_name;
    cmd_func_t cmd_func;

    /* Initialize command registry */
    init_commands();
    
    /* ====== NEW: Handle --commands-json flag ====== */
    if (argc >= 2 && strcmp(argv[1], "--commands-json") == 0) {
        print_commands_json();
        return EXIT_OK;
    }
    /* ============================================== */

    /* Handle empty arguments */
    if (argc < 1 || argv[0] == NULL) {
        fprintf(stderr, "picobox: invalid invocation\n");
        return EXIT_ERROR;
    }
    
    /* ... rest of existing code ... */
}
```

**Detailed Explanation**:
- Check happens early, before any other processing
- Must be after `init_commands()` so registry is populated
- Returns immediately after printing JSON (no shell startup)
- Exit code is EXIT_OK so calling process knows it succeeded

#### **2.3: Test JSON Output**

**Test 1: Verify JSON is generated**
```bash
# Compile
make clean
make

# Run command
./picobox --commands-json

# Expected output: Valid JSON starting with {"commands":[...]}
```

**Test 2: Validate JSON syntax**
```bash
./picobox --commands-json | python3 -m json.tool > /dev/null
echo $?  # Should be 0 (success)
```

**Test 3: Check command count**
```bash
./picobox --commands-json | python3 -c "
import json, sys
data = json.load(sys.stdin)
print(f'Found {len(data[\"commands\"])} commands')
"

# Expected: Found 27 commands (or however many you have)
```

**Test 4: Verify specific command details**
```bash
./picobox --commands-json | python3 -c "
import json, sys
data = json.load(sys.stdin)
echo_cmd = next(c for c in data['commands'] if c['name'] == 'echo')
print('Echo command:')
print(f'  Name: {echo_cmd[\"name\"]}')
print(f'  Summary: {echo_cmd[\"summary\"]}')
print(f'  Description: {echo_cmd[\"description\"][:50]}...')
"
```

**Test 5: Ensure normal shell still works**
```bash
# Shell should still start normally
./picobox
$ echo test
test
$ exit
```

**Checkpoint**: You should have:
- âœ… Valid JSON output from `picobox --commands-json`
- âœ… All 27 commands in the JSON
- âœ… Each command has name, summary, description, usage fields
- âœ… Normal shell functionality unchanged

**Git Commit**:
```bash
git add main.c
git commit -m "Add --commands-json flag for AI integration

- Implement print_commands_json() to export command catalog
- Check for --commands-json flag in main()
- Output valid JSON with all registered commands
- Tested: JSON validates, contains all commands
"
```

---

### **PHASE 3: Add mysh_llm.py Script**
**Time Estimate**: 30 minutes

Copy and configure the professor's Python script.

#### **3.1: Copy Script to Project**

```bash
# Create the file
cat > mysh_llm.py << 'PYTHON_SCRIPT_HERE'
# (Paste the entire professor's script from the document)
PYTHON_SCRIPT_HERE

# Make executable
chmod +x mysh_llm.py

# Verify it's readable
head -20 mysh_llm.py
```

#### **3.2: Understand Script Structure**

Read through and document key functions:

```python
# Key Functions in mysh_llm.py:

# 1. load_command_catalog() â†’ List[CommandInfo]
#    - Tries: run_catalog_command() â†’ "picobox --commands-json"
#    - Falls back to: load_catalog_from_file() â†’ "commands.json"
#    - Returns: List of CommandInfo objects

# 2. score_command(query, cmd) â†’ int
#    - Simple keyword matching (RAG without embeddings)
#    - Scores based on: name (3x), summary (2x), description (1x)
#    - Higher score = more relevant

# 3. select_relevant_commands(query, catalog, k=5) â†’ List[CommandInfo]
#    - Scores all commands
#    - Returns top k commands (default 5)
#    - This is the RAG retrieval step

# 4. build_prompt(query, catalog) â†’ str
#    - Gets top 5 relevant commands
#    - Builds prompt with command docs
#    - This is what gets sent to LLM

# 5. call_llm(prompt) â†’ Optional[str]
#    - Calls OpenAI API if configured
#    - Returns None if not configured
#    - Returns suggested command if successful

# 6. heuristic_suggestion(query, catalog) â†’ str
#    - Fallback when LLM not available
#    - Very simple: picks most relevant command
#    - Returns basic command line

# 7. suggest_command(query) â†’ str
#    - Main entry point
#    - Tries LLM first, falls back to heuristic
#    - Always returns something

# 8. main(argv) â†’ int
#    - Entry point from shell
#    - Gets query from argv[1]
#    - Prints ONE line (the suggestion)
#    - Returns 0
```

#### **3.3: Test Script Standalone**

**Test 1: Run without API key (heuristic fallback)**
```bash
# Unset API key temporarily
unset OPENAI_API_KEY

# Set path to shell
export MYSH_PATH=./picobox
export MYSH_CATALOG_CMD='./picobox --commands-json'

# Test basic query
python3 mysh_llm.py "list files"

# Expected output: ls (or similar, one line only)
```

**Test 2: Test with various queries**
```bash
# Test file listing
python3 mysh_llm.py "show all files"
# Expected: ls

# Test counting
python3 mysh_llm.py "count lines"
# Expected: wc

# Test searching
python3 mysh_llm.py "find text files"
# Expected: find or grep (one of these)

# Test copying
python3 mysh_llm.py "copy a file"
# Expected: cp
```

**Test 3: Test with API key (if available)**
```bash
# Set API key
export OPENAI_API_KEY='sk-your-key'

# Enable debug output
export MYSH_LLM_DEBUG=1

# Test query
python3 mysh_llm.py "show me all .c files modified today" 2>&1

# Expected stderr: Debug output showing LLM call
# Expected stdout: Command like "find . -name '*.c' -mtime 0"
```

**Test 4: Verify output format**
```bash
# Output should be exactly ONE line, no newline
python3 mysh_llm.py "list files" | wc -l
# Expected: 0 (no newline) or 1 (one line)

# Output should be a valid command
CMD=$(python3 mysh_llm.py "list files")
echo "Suggested: $CMD"
# Should be readable
```

**Test 5: Test error cases**
```bash
# Empty query
python3 mysh_llm.py ""
# Expected: echo "LLM helper: empty query"

# No arguments
python3 mysh_llm.py
# Expected: echo "Usage: mysh_llm <natural language query>"

# Shell binary not found
unset MYSH_PATH
python3 mysh_llm.py "test"
# Expected: Falls back to heuristic (no catalog available)
```

**Checkpoint**: You should have:
- âœ… mysh_llm.py script in project directory
- âœ… Script runs standalone
- âœ… Heuristic fallback works (without API key)
- âœ… LLM mode works (with API key, if available)
- âœ… Output is exactly one line

**Git Commit**:
```bash
git add mysh_llm.py
git commit -m "Add mysh_llm.py AI helper script

- Professor's implementation with RAG and LLM support
- Works with or without OpenAI API key
- Fallback to heuristic suggestions
- Tested: standalone execution, various queries
"
```

---

### **PHASE 4: Add @ Detection to shell_bnfc.c**
**Time Estimate**: 2 hours (including extensive testing)

This is the core integration. The shell must detect `@` prefix and call the Python script.

#### **4.1: Add handle_llm_query() Function**

**File**: `shell_bnfc.c`

**Location**: After the built-in command functions (after `builtin_cd()`)

**Implementation**:
```c
/*
 * Handle AI query (lines starting with @)
 * 
 * This is called when user types: @show me all files
 * 
 * Process:
 * 1. Call Python script: python3 mysh_llm.py "show me all files"
 * 2. Read suggestion from script output
 * 3. Display suggestion to user with formatting
 * 4. Get y/n confirmation
 * 5. If yes: parse and execute suggestion via BNFC
 * 
 * The Python script is responsible for:
 * - Getting command catalog from shell (via --commands-json)
 * - Scoring commands for relevance (RAG)
 * - Calling LLM or using heuristic fallback
 * - Printing ONE line (the suggested command)
 * 
 * The shell is responsible for:
 * - Parsing the suggestion (via BNFC)
 * - Asking user for confirmation (safety)
 * - Executing the command (normal pipeline)
 */
static void handle_llm_query(const char *query)
{
    char cmd[2048];
    char suggestion[1024];
    FILE *fp;
    char answer;
    int c;

    /* Validate input */
    if (!query || query[0] == '\0') {
        fprintf(stderr, "Error: Empty query\n");
        return;
    }

    /* Build command to call Python helper
     * 
     * Uses environment variable MYSH_LLM_SCRIPT for flexibility:
     * - Default: python3 mysh_llm.py
     * - Can be overridden for testing
     */
    const char *llm_script = getenv("MYSH_LLM_SCRIPT");
    if (!llm_script) {
        llm_script = "python3 mysh_llm.py";
    }

    /* Escape query for shell (basic escaping, may need improvement) */
    /* For now, assuming query doesn't contain quotes */
    snprintf(cmd, sizeof(cmd), "%s \"%s\" 2>&1", llm_script, query);

    /* Call Python helper and capture output
     * 
     * popen() creates a pipe and forks a child process.
     * The child runs the Python script.
     * The parent (us) reads from the pipe.
     */
    fp = popen(cmd, "r");
    if (!fp) {
        perror("popen");
        fprintf(stderr, "Error: Failed to run AI helper script.\n");
        fprintf(stderr, "Make sure mysh_llm.py is in your PATH or current directory.\n");
        return;
    }

    /* Read suggestion from Python script
     * 
     * IMPORTANT: Script outputs EXACTLY ONE LINE
     * This is the suggested command.
     * Script may also output debug info to stderr (which we see in 2>&1)
     */
    if (fgets(suggestion, sizeof(suggestion), fp) == NULL) {
        fprintf(stderr, "Error: AI helper returned no suggestion.\n");
        fprintf(stderr, "Possible causes:\n");
        fprintf(stderr, "  - OPENAI_API_KEY not set (will use fallback)\n");
        fprintf(stderr, "  - Script error (check debug output above)\n");
        fprintf(stderr, "  - Shell --commands-json not working\n");
        pclose(fp);
        return;
    }

    /* Remove trailing newline from suggestion */
    suggestion[strcspn(suggestion, "\n")] = '\0';

    /* Close pipe and check exit status */
    int status = pclose(fp);
    if (status != 0) {
        fprintf(stderr, "Warning: AI helper exited with status %d\n", status);
        /* Continue anyway - suggestion might still be valid */
    }

    /* Skip if suggestion is empty */
    if (strlen(suggestion) == 0) {
        fprintf(stderr, "Error: AI helper returned empty suggestion.\n");
        return;
    }

    /* Display suggestion to user with nice formatting
     * 
     * Use ANSI color codes for better visibility:
     * - \033[1;32m = Bold Green
     * - \033[0m = Reset
     */
    printf("\n");
    printf("ðŸ’¡ AI Suggested Command:\n");
    printf("   \033[1;32m%s\033[0m\n", suggestion);
    printf("\n");
    printf("Run this command? (y/n): ");
    fflush(stdout);

    /* Get user confirmation
     * 
     * IMPORTANT: This is a safety feature!
     * Never execute AI-suggested commands without user approval.
     * The AI might hallucinate dangerous commands.
     */
    if (scanf(" %c", &answer) != 1) {
        fprintf(stderr, "Error: Failed to read answer\n");
        /* Clear input buffer */
        while ((c = getchar()) != '\n' && c != EOF);
        return;
    }
    
    /* Clear rest of input line */
    while ((c = getchar()) != '\n' && c != EOF);

    /* Check if user approved */
    if (answer != 'y' && answer != 'Y') {
        printf("Command cancelled.\n");
        return;
    }

    /* User approved - parse and execute suggestion
     * 
     * CRITICAL: We use the SAME execution path as normal commands
     * This ensures the suggestion goes through:
     * - BNFC parsing (syntax checking)
     * - Visitor pattern execution
     * - Normal error handling
     * 
     * This is MUCH safer than directly calling system() or exec()
     */
    printf("\n");
    
    /* Parse suggestion using BNFC parser */
    Input ast = psInput(suggestion);
    
    if (ast == NULL) {
        fprintf(stderr, "Parse error: AI suggestion has invalid syntax\n");
        fprintf(stderr, "Suggestion was: %s\n", suggestion);
        fprintf(stderr, "This might be a bug in the AI helper.\n");
        return;
    }

    /* Execute using visitor pattern (same as normal commands) */
    ExecContext *ctx = exec_context_new();
    if (!ctx) {
        fprintf(stderr, "Error: Failed to create execution context\n");
        free_Input(ast);
        return;
    }

    /* Execute the command */
    visitInput(ast, ctx);

    /* Check for errors */
    if (ctx->has_error) {
        fprintf(stderr, "Error: Command execution failed\n");
    }

    /* Check if command was 'exit' */
    if (ctx->should_exit) {
        printf("Note: AI suggested 'exit' - not executing for safety\n");
        ctx->should_exit = 0;  /* Don't actually exit */
    }

    /* Cleanup */
    exec_context_free(ctx);
    free_Input(ast);
}
```

**Detailed Explanation**:

1. **Query Validation**: Check for empty/NULL query
2. **Command Building**: Use `snprintf()` to safely build command
3. **popen() Call**: Fork Python script, get pipe to its stdout
4. **Read Suggestion**: Read exactly one line from script
5. **User Confirmation**: Display suggestion, ask y/n
6. **Parse & Execute**: Use BNFC parser + visitor (normal path)
7. **Safety Checks**: Validate parse, check errors, prevent 'exit'
8. **Cleanup**: Free AST, close pipe, free context

**Why This is Safe**:
- AI output goes through BNFC parser (syntax validation)
- User must explicitly approve (no auto-execution)
- Uses same execution path as manual commands
- Prevents dangerous commands like 'exit' in suggestions
- Proper error handling at every step

#### **4.2: Modify REPL Loop for @ Detection**

**File**: `shell_bnfc.c`

**Location**: In `shell_bnfc_main_visitor()` function

**Find this code**:
```c
while (1) {
    /* Print prompt */
    printf("%s", PROMPT);
    fflush(stdout);

    /* Read line */
    if (fgets(line, sizeof(line), stdin) == NULL) {
        /* EOF (Ctrl+D) */
        printf("\n");
        break;
    }

    /* Remove newline */
    size_t len = strlen(line);
    if (len > 0 && line[len - 1] == '\n') {
        line[len - 1] = '\0';
    }

    /* Skip empty lines */
    if (line[0] == '\0') {
        continue;
    }

    /* Parse the line using BNFC parser */
    ast = psInput(line);
    
    /* ... rest of loop ... */
}
```

**Replace with**:
```c
while (1) {
    /* Print prompt */
    printf("%s", PROMPT);
    fflush(stdout);

    /* Read line */
    if (fgets(line, sizeof(line), stdin) == NULL) {
        /* EOF (Ctrl+D) */
        printf("\n");
        break;
    }

    /* Remove newline */
    size_t len = strlen(line);
    if (len > 0 && line[len - 1] == '\n') {
        line[len - 1] = '\0';
    }

    /* Skip empty lines */
    if (line[0] == '\0') {
        continue;
    }

    /* ====== NEW: Check for AI query (@ prefix) ====== */
    /* 
     * If line starts with @, it's an AI query.
     * 
     * We handle this BEFORE calling psInput() so the grammar
     * never sees the @ character.
     * 
     * This keeps our existing AICmd grammar rule completely
     * independent - "AI how do I..." still works via BNFC.
     * 
     * Examples:
     *   @show all files      â†’ AI helper
     *   AI how do I list     â†’ BNFC parser â†’ AICmd
     *   ls -la               â†’ BNFC parser â†’ SimpleCmd
     */
    if (line[0] == '@') {
        /* Skip the @ and pass rest to AI helper */
        handle_llm_query(line + 1);
        continue;  /* Go back to prompt, don't parse with BNFC */
    }
    /* ================================================= */

    /* Parse the line using BNFC parser (as before) */
    ast = psInput(line);
    
    /* ... rest of loop unchanged ... */
}
```

**Detailed Explanation**:

1. **Order is Critical**: The `@` check happens BEFORE `psInput()`
2. **String Pointer Arithmetic**: `line + 1` skips the `@` character
3. **Early Continue**: `continue` jumps back to top of loop, skipping parser
4. **Independence**: This doesn't interfere with existing `AICmd` grammar
5. **Clear Comments**: Explain why we do this for future maintainers

#### **4.3: Update Help Message**

**File**: `shell_bnfc.c`

**Location**: In `builtin_help()` function

**Find this code**:
```c
static int builtin_help(int argc, char **argv)
{
    (void)argc;
    (void)argv;

    printf("PicoBox BNFC Shell v%s (Phase 4: Fork/Exec)\n", PICOBOX_VERSION);
    printf("Interactive command-line interface (BNFC-powered)\n\n");
    printf("Built-in commands:\n");
    printf("  exit       - Exit the shell\n");
    printf("  help       - Show this help message\n");
    printf("  cd [DIR]   - Change directory\n\n");
    printf("External commands:\n");
    printf("  Any command in your PATH (e.g., ls, cat, echo, grep, etc.)\n");
    printf("  Commands are executed in separate processes via fork/exec\n\n");
    printf("For help on a specific command, use: <command> --help\n");
    return EXIT_OK;
}
```

**Replace with**:
```c
static int builtin_help(int argc, char **argv)
{
    (void)argc;
    (void)argv;

    printf("PicoBox BNFC Shell v%s (Phase 7: AI Integration)\n", PICOBOX_VERSION);
    printf("Interactive command-line interface (BNFC-powered)\n\n");
    
    printf("Built-in commands:\n");
    printf("  exit       - Exit the shell\n");
    printf("  help       - Show this help message\n");
    printf("  cd [DIR]   - Change directory\n\n");
    
    printf("External commands:\n");
    printf("  Any command in your PATH (e.g., ls, cat, echo, grep, etc.)\n");
    printf("  Commands are executed in separate processes via fork/exec\n\n");
    
    /* ====== NEW: Document both AI features ====== */
    printf("AI Assistant (Two Ways):\n");
    printf("  @<query>         - New: Natural language to command suggestion\n");
    printf("                     Example: @show me all .c files\n");
    printf("                     Uses: mysh_llm.py with RAG + LLM\n");
    printf("  AI <question>    - Legacy: Direct AI chat (grammar-based)\n");
    printf("                     Example: AI how do I list files\n");
    printf("                     Uses: cmd_ai.c with OpenAI API\n\n");
    /* ============================================= */
    
    printf("Pipelines & Redirections:\n");
    printf("  cmd1 | cmd2      - Pipeline (stdout of cmd1 â†’ stdin of cmd2)\n");
    printf("  cmd < file       - Input redirection\n");
    printf("  cmd > file       - Output redirection\n");
    printf("  cmd >> file      - Append output\n");
    printf("  cmd1 ; cmd2      - Command sequence\n\n");
    
    printf("For help on a specific command, use: <command> --help\n");
    return EXIT_OK;
}
```

#### **4.4: Update Shell Startup Banner**

**File**: `shell_bnfc.c`

**Location**: In `shell_bnfc_main_visitor()`, before the REPL loop

**Find this code**:
```c
printf("PicoBox BNFC Shell v%s (Visitor Pattern + Registry)\n", PICOBOX_VERSION);
printf("Type 'help' for available commands, 'exit' to quit.\n");
printf("Refactored commands available: echo, pwd, true, false (using argtable3)\n");
printf("Using VISITOR PATTERN for AST traversal (industry standard)\n\n");
```

**Replace with**:
```c
printf("PicoBox BNFC Shell v%s (Visitor Pattern + Registry + AI)\n", PICOBOX_VERSION);
printf("Type 'help' for available commands, 'exit' to quit.\n");
printf("Features: 27+ commands, pipelines, redirections, dual AI systems\n");
printf("\n");
printf("ðŸ’¡ Try the AI assistant:\n");
printf("   @show me all files        (New: mysh_llm.py with RAG)\n");
printf("   AI how do I list files    (Legacy: cmd_ai.c)\n");
printf("\n");
```

**Reasoning**: Users should know about both AI features from the start.

#### **4.5: Test @ Detection Thoroughly**

This is the most critical testing phase. We must verify:
1. @ detection works
2. Python script is called correctly
3. Suggestions are displayed properly
4. User confirmation works
5. Execution works via BNFC parser
6. Normal commands still work
7. AICmd grammar still works

**Test 1: Compile and Basic Smoke Test**
```bash
# Compile
make clean
make

# Start shell
./picobox
```

**Expected output**:
```
PicoBox BNFC Shell v1.0 (Visitor Pattern + Registry + AI)
Type 'help' for available commands, 'exit' to quit.
Features: 27+ commands, pipelines, redirections, dual AI systems

ðŸ’¡ Try the AI assistant:
   @show me all files        (New: mysh_llm.py with RAG)
   AI how do I list files    (Legacy: cmd_ai.c)

$ 
```

**Test 2: Test Normal Commands (Regression Test)**
```bash
$ ls
# Should list files normally

$ echo test
test

$ cat mysh_llm.py | head -5
# Should show first 5 lines

$ exit
# Should exit normally
```

**Expected**: All normal commands work exactly as before.

**Test 3: Test Legacy AI Command (AICmd)**
```bash
$ AI how do I list files
ðŸ¤” Thinking...
âœ¨ You can use the 'ls' command to list files...
```

**Expected**: Your existing `cmd_ai.c` still works (proves independence).

**Test 4: Test @ Detection (Basic)**
```bash
$ @list files
ðŸ’¡ AI Suggested Command:
   ls

Run this command? (y/n): n
Command cancelled.
$ 
```

**Expected**: 
- Suggestion is displayed
- User is prompted
- 'n' cancels without executing

**Test 5: Test @ Detection (With Execution)**
```bash
$ @show all files
ðŸ’¡ AI Suggested Command:
   ls -la

Run this command? (y/n): y

total 512
drwxr-xr-x  10 user user  4096 Dec  3 23:30 .
drwxr-xr-x  20 user user  4096 Dec  3 20:00 ..
-rw-r--r--   1 user user  8543 Dec  3 23:28 main.c
-rw-r--r--   1 user user 23456 Dec  3 23:29 shell_bnfc.c
-rwxr-xr-x   1 user user  8632 Dec  3 23:27 mysh_llm.py
...

$ 
```

**Expected**: Command executes and output is displayed.

**Test 6: Test Complex Query**
```bash
$ @find all C source files modified today
ðŸ’¡ AI Suggested Command:
   find . -name "*.c" -mtime 0

Run this command? (y/n): y

./main.c
./shell_bnfc.c
./cmd_echo.c
...

$ 
```

**Expected**: More complex command is suggested and executed correctly.

**Test 7: Test Query With Pipes**
```bash
$ @count lines in all python files
ðŸ’¡ AI Suggested Command:
   find . -name "*.py" -exec wc -l {} +

Run this command? (y/n): y

  300 ./mysh_llm.py
  150 ./test.py
  450 total

$ 
```

**Expected**: Pipeline commands work through the AI assistant.

**Test 8: Test Empty Query**
```bash
$ @
Error: Empty query
$ 
```

**Expected**: Graceful error handling.

**Test 9: Test Query With Special Characters**
```bash
$ @show files with "quotes"
ðŸ’¡ AI Suggested Command:
   ls
   
Run this command? (y/n): y
...
$ 
```

**Expected**: Query is handled safely (though escaping may need work).

**Test 10: Test Invalid Suggestion**
```bash
# This test requires modifying Python script temporarily
# or finding a query that produces invalid syntax

$ @do something impossible
ðŸ’¡ AI Suggested Command:
   xyz123nonsense

Run this command? (y/n): y

Parse error: AI suggestion has invalid syntax
Suggestion was: xyz123nonsense
This might be a bug in the AI helper.

$ 
```

**Expected**: Parser catches invalid syntax, doesn't crash.

**Test 11: Test Without API Key (Fallback)**
```bash
# In another terminal
export MYSH_PATH=./picobox
unset OPENAI_API_KEY

# Start shell
./picobox

$ @list files
ðŸ’¡ AI Suggested Command:
   ls

Run this command? (y/n): y
...
$ 
```

**Expected**: Heuristic fallback works without OpenAI.

**Test 12: Test With Debug Output**
```bash
# In another terminal
export MYSH_LLM_DEBUG=1
export OPENAI_API_KEY='your-key'

./picobox

$ @show me all files
[mysh_llm] Running catalog command: ./picobox --commands-json
[mysh_llm] LLM suggestion: ls -la

ðŸ’¡ AI Suggested Command:
   ls -la

Run this command? (y/n): y
...
$ 
```

**Expected**: Debug output appears, helps with troubleshooting.

**Test 13: Test Help Command**
```bash
$ help

PicoBox BNFC Shell v1.0 (Phase 7: AI Integration)
...

AI Assistant (Two Ways):
  @<query>         - New: Natural language to command suggestion
                     Example: @show me all .c files
                     Uses: mysh_llm.py with RAG + LLM
  AI <question>    - Legacy: Direct AI chat (grammar-based)
                     Example: AI how do I list files
                     Uses: cmd_ai.c with OpenAI API
...

$ 
```

**Expected**: Help clearly documents both AI systems.

**Test 14: Stress Test (Many Queries)**
```bash
$ @list files
$ @find C files
$ @count lines
$ @show hidden files
$ @search for text
$ @copy files
$ @remove files
$ @create directory
$ @change permissions
$ @show disk usage
```

**Expected**: Shell handles repeated queries without issues.

**Test 15: Test After Other Commands**
```bash
$ ls
$ cd /tmp
$ pwd
/tmp
$ @show files here
ðŸ’¡ AI Suggested Command:
   ls

Run this command? (y/n): y
... (shows /tmp contents)
$ 
```

**Expected**: @ detection works anywhere in the session.

**Checkpoint**: You should have:
- âœ… @ detection working before BNFC parser
- âœ… Python script is called and output is captured
- âœ… Suggestions are displayed with formatting
- âœ… User confirmation prompts work
- âœ… Approved commands execute via BNFC parser
- âœ… Normal commands still work (no regression)
- âœ… Legacy AICmd still works (independence)
- âœ… Error handling for edge cases
- âœ… Help message documents both AI systems

**Git Commit**:
```bash
git add shell_bnfc.c
git commit -m "Add @ prefix AI query handling

- Implement handle_llm_query() function
- Add @ detection before BNFC parsing
- User confirmation for AI suggestions
- Execute suggestions via normal BNFC pipeline
- Update help message for both AI systems
- Tested: 15 test cases, all passing
- Legacy AICmd still works (independent)
"
```

---

### **PHASE 5: Advanced Testing & Edge Cases**
**Time Estimate**: 1-2 hours

Now that basic functionality works, we need to test edge cases and potential problems.

#### **5.1: Test Concurrent Shell Instances**

```bash
# Terminal 1
./picobox
$ @list files

# Terminal 2
./picobox
$ @count lines

# Both should work independently
```

**Expected**: Both instances work without interfering.

#### **5.2: Test With Different Environment Configs**

**Test Config 1: No API Key**
```bash
unset OPENAI_API_KEY
./picobox
$ @list files
# Should use heuristic fallback
```

**Test Config 2: Custom Model**
```bash
export MYSH_LLM_MODEL='gpt-4'
./picobox
$ @list files
# Should use GPT-4 (if you have access)
```

**Test Config 3: Custom Script Path**
```bash
export MYSH_LLM_SCRIPT='/usr/local/bin/mysh_llm.py'
./picobox
$ @list files
# Should call script from custom location
```

#### **5.3: Test Error Recovery**

**Test 1: Python script not found**
```bash
# Rename script temporarily
mv mysh_llm.py mysh_llm.py.bak

./picobox
$ @list files
Error: Failed to run AI helper script.
Make sure mysh_llm.py is in your PATH or current directory.

$ ls  # Normal commands still work
...

$ exit

# Restore script
mv mysh_llm.py.bak mysh_llm.py
```

**Expected**: Graceful error, shell continues working.

**Test 2: Shell --commands-json broken**
```bash
# Temporarily break JSON output
# (comment out print_commands_json in main.c)

./picobox
$ @list files
# Should fall back to heuristic (no catalog)
ðŸ’¡ AI Suggested Command:
   ls
...
```

**Expected**: Fallback works even without catalog.

**Test 3: Invalid JSON from shell**
```bash
# Modify print_commands_json to output invalid JSON
# (add extra comma or remove closing brace)

./picobox
$ @list files
# Python script should handle gracefully
```

**Expected**: Error message, fallback to heuristic.

#### **5.4: Test Integration With Other Features**

**Test 1: @ Query After Pipeline**
```bash
$ cat file.txt | grep test | wc -l
5
$ @show me the file
ðŸ’¡ AI Suggested Command:
   cat file.txt
...
```

**Expected**: @ works after pipelines.

**Test 2: @ Query With Redirections**
```bash
$ echo test > file.txt
$ @show contents of file.txt
ðŸ’¡ AI Suggested Command:
   cat file.txt

Run this command? (y/n): y
test
```

**Expected**: @ works with redirections in history.

**Test 3: Pipeline After @ Query**
```bash
$ @list files
ðŸ’¡ AI Suggested Command:
   ls

Run this command? (y/n): y
...

$ ls | wc -l
15
```

**Expected**: Normal commands work after @ queries.

#### **5.5: Test Memory and Resource Usage**

```bash
# Install valgrind if not already
sudo apt-get install valgrind

# Run shell under valgrind
valgrind --leak-check=full ./picobox

$ @list files
$ @count lines
$ @find files
$ exit

# Check for memory leaks
```

**Expected**: No memory leaks, all allocations freed.

#### **5.6: Test Performance**

```bash
# Time how long AI queries take
time (echo "@list files" | ./picobox)

# Time normal commands for comparison
time (echo "ls" | ./picobox)
```

**Expected**: @ queries are slower (network call) but acceptable (<5 seconds).

#### **5.7: Create Automated Test Script**

**File**: `test_ai_integration.sh`

```bash
#!/bin/bash
# Automated test suite for AI integration

set -e  # Exit on error

echo "=== AI Integration Test Suite ==="
echo ""

# Setup
export MYSH_PATH=./picobox
export MYSH_CATALOG_CMD='./picobox --commands-json'
unset OPENAI_API_KEY  # Use heuristic for reproducibility

# Test 1: JSON output
echo "[Test 1] JSON output"
./picobox --commands-json | python3 -m json.tool > /dev/null
echo "  âœ“ JSON is valid"

# Test 2: Command count
echo "[Test 2] Command catalog"
COUNT=$(./picobox --commands-json | python3 -c "import json,sys; print(len(json.load(sys.stdin)['commands']))")
if [ "$COUNT" -ge 20 ]; then
    echo "  âœ“ Found $COUNT commands"
else
    echo "  âœ— ERROR: Only found $COUNT commands"
    exit 1
fi

# Test 3: Python script standalone
echo "[Test 3] Python script"
OUTPUT=$(python3 mysh_llm.py "list files")
if [ -n "$OUTPUT" ]; then
    echo "  âœ“ Script returned: $OUTPUT"
else
    echo "  âœ— ERROR: Script returned nothing"
    exit 1
fi

# Test 4: Shell integration (automated)
echo "[Test 4] Shell integration"
OUTPUT=$(echo -e "@list files\nn\nexit" | ./picobox | grep "AI Suggested")
if [ -n "$OUTPUT" ]; then
    echo "  âœ“ @ detection working"
else
    echo "  âœ— ERROR: @ detection not working"
    exit 1
fi

# Test 5: Normal commands still work
echo "[Test 5] Regression test"
OUTPUT=$(echo -e "echo test\nexit" | ./picobox | grep "test")
if [ -n "$OUTPUT" ]; then
    echo "  âœ“ Normal commands work"
else
    echo "  âœ— ERROR: Normal commands broken"
    exit 1
fi

echo ""
echo "=== All Tests Passed ==="
```

**Run tests**:
```bash
chmod +x test_ai_integration.sh
./test_ai_integration.sh
```

**Expected**: All tests pass.

**Git Commit**:
```bash
git add test_ai_integration.sh
git commit -m "Add automated test suite for AI integration

- Test JSON output validation
- Test command catalog completeness
- Test Python script standalone
- Test @ detection in shell
- Test regression (normal commands)
- All tests passing
"
```

---

### **PHASE 6: Documentation & Cleanup**
**Time Estimate**: 1 hour

Create comprehensive documentation for future maintenance and users.

#### **6.1: Create User Guide**

**File**: `AI_USER_GUIDE.md`

```markdown
# PicoBox Shell AI Assistant - User Guide

## Overview

PicoBox shell has TWO AI assistant features:

1. **@ Prefix System** (New, Recommended)
   - Syntax: `@<natural language query>`
   - Example: `@show me all .c files`
   - Uses: mysh_llm.py with RAG + LLM
   - Requires: OPENAI_API_KEY (or uses fallback)

2. **AI Command** (Legacy)
   - Syntax: `AI <question>`
   - Example: `AI how do I list files`
   - Uses: cmd_ai.c with OpenAI API
   - Requires: AI_SHELL environment variable

## Quick Start

### Setup

1. Set environment variables:
```bash
export OPENAI_API_KEY='your-key-here'
export MYSH_PATH=./picobox
```

2. Start shell:
```bash
./picobox
```

### Using @ Prefix System

```bash
$ @list all files
ðŸ’¡ AI Suggested Command:
   ls -la

Run this command? (y/n): y
# (command executes)
```

### Using AI Command

```bash
$ AI how do I find large files
ðŸ¤” Thinking...
âœ¨ Use: find . -type f -size +100M
```

## Examples

### File Operations
```bash
@show me all files
@find python files
@count lines in C files
@show hidden files
```

### Searching
```bash
@search for "error" in logs
@find files modified today
@show files larger than 1MB
```

### File Management
```bash
@copy all images to backup
@remove temporary files
@create a new directory
```

### System Info
```bash
@show disk usage
@check free space
@list running processes
```

## Features

- **RAG (Retrieval-Augmented Generation)**: AI only suggests commands that exist
- **User Confirmation**: You must approve before execution
- **Safe Execution**: Commands parsed by BNFC, same as manual entry
- **Fallback Mode**: Works without API key (basic heuristics)

## Configuration

### Environment Variables

- `OPENAI_API_KEY`: Your OpenAI API key
- `MYSH_PATH`: Path to picobox binary (default: picobox)
- `MYSH_CATALOG_CMD`: Command to get catalog (default: mysh --commands-json)
- `MYSH_LLM_MODEL`: OpenAI model to use (default: gpt-4o-mini)
- `MYSH_LLM_DEBUG`: Enable debug output (set to 1)
- `MYSH_LLM_SCRIPT`: Path to mysh_llm.py (default: python3 mysh_llm.py)

### Example .env File

```bash
export OPENAI_API_KEY='sk-your-key'
export MYSH_PATH='./picobox'
export MYSH_LLM_DEBUG=1
```

Load with: `source .env`

## Troubleshooting

### "Failed to run AI helper script"
- Check mysh_llm.py is in current directory or PATH
- Make sure it's executable: `chmod +x mysh_llm.py`

### "AI helper returned no suggestion"
- Check OPENAI_API_KEY is set
- Enable debug: `export MYSH_LLM_DEBUG=1`
- Try without API key (uses fallback)

### "Parse error: AI suggestion has invalid syntax"
- AI hallucinated invalid command
- Report the query as a bug
- Try rephrasing your question

### Slow Response
- Network latency to OpenAI API (normal)
- Try faster model: `export MYSH_LLM_MODEL=gpt-3.5-turbo`
- Use fallback mode (no API key)

## Safety

- **NEVER execute AI suggestions blindly**
- Always read the suggested command before approving
- AI can hallucinate dangerous commands
- User confirmation is required for every suggestion
- Commands are parsed by BNFC (syntax validation)

## Comparison: @ vs AI Command

| Feature | @ Prefix | AI Command |
|---------|----------|------------|
| Output | Command to run | Explanation |
| Execution | User confirms | Not executed |
| API Calls | One (to OpenAI) | One (to OpenAI) |
| Fallback | Yes (heuristic) | No |
| RAG | Yes | No |
| Grammar | None (pre-parser) | AICmd rule |

## Tips

1. **Be specific**: "@find .c files" is better than "@find files"
2. **Use verbs**: "show", "list", "find", "count", "search"
3. **Mention file types**: "python files", ".txt files"
4. **Add constraints**: "modified today", "larger than 1MB"
5. **Try alternatives**: If suggestion is wrong, rephrase

## Examples of Good Queries

âœ… "show me all C source files"
âœ… "find files modified in the last hour"
âœ… "count lines in all Python files"
âœ… "search for TODO in C files"
âœ… "show disk usage of current directory"

## Examples of Bad Queries

âŒ "files" (too vague)
âŒ "what's in this directory" (use: "list files")
âŒ "help me with something" (no context)
âŒ "do the thing" (not specific)

## Advanced

### Using Without OpenAI

```bash
unset OPENAI_API_KEY
./picobox
$ @list files
# Uses heuristic fallback
```

### Custom Python Script

```bash
export MYSH_LLM_SCRIPT='/path/to/custom_script.py'
```

### Debugging

```bash
export MYSH_LLM_DEBUG=1
./picobox
$ @test query
[mysh_llm] Running catalog command: ./picobox --commands-json
[mysh_llm] LLM suggestion: ls
...
```

## Future Enhancements

Planned features:
- Multiple suggestions (choose from top 3)
- Command history learning
- Local LLM support (Ollama)
- Better scoring algorithm
- Context awareness (current directory, recent commands)
```

#### **6.2: Create Developer Guide**

**File**: `AI_DEVELOPER_GUIDE.md`

```markdown
# PicoBox Shell AI Integration - Developer Guide

## Architecture Overview

### Components

1. **main.c**: Exports command catalog via `--commands-json`
2. **shell_bnfc.c**: Detects @ prefix, calls Python script
3. **mysh_llm.py**: Scores commands, calls LLM, returns suggestion

### Data Flow

```
User: @show files
    â†“
shell_bnfc.c: handle_llm_query()
    â†“
popen("python3 mysh_llm.py \"show files\"")
    â†“
mysh_llm.py: load_command_catalog()
    â†“
subprocess.run(["picobox", "--commands-json"])
    â†“
main.c: print_commands_json()
    â†“
JSON output â†’ Python parses
    â†“
mysh_llm.py: score_command() (RAG)
    â†“
mysh_llm.py: call_llm() (OpenAI API)
    â†“
Suggestion printed to stdout
    â†“
shell_bnfc.c: reads suggestion
    â†“
Display to user, get confirmation
    â†“
psInput() parses suggestion
    â†“
visitInput() executes
```

## Code Organization

### main.c Changes

```c
// Added function
static void print_commands_json(void);

// Modified function
int main(int argc, char **argv) {
    init_commands();
    
    // NEW: Check for --commands-json
    if (argc >= 2 && strcmp(argv[1], "--commands-json") == 0) {
        print_commands_json();
        return EXIT_OK;
    }
    
    // ... rest unchanged
}
```

### shell_bnfc.c Changes

```c
// Added function
static void handle_llm_query(const char *query);

// Modified function
int shell_bnfc_main_visitor(void) {
    while (1) {
        fgets(line, sizeof(line), stdin);
        
        // NEW: Check for @ prefix
        if (line[0] == '@') {
            handle_llm_query(line + 1);
            continue;
        }
        
        // ... rest unchanged
    }
}
```

## Critical Implementation Details

### Why @ Detection is Before Parser

```c
/* CORRECT ORDER */
if (line[0] == '@') {
    handle_llm_query(line + 1);
    continue;  // Skip psInput()
}
ast = psInput(line);  // Only reached for non-@ lines
```

If we checked after parsing, the parser would fail on `@` (not in grammar).

### Why We Use popen()

```c
FILE *fp = popen("python3 mysh_llm.py \"query\"", "r");
```

Alternatives considered:
- `system()`: Can't capture output
- `fork() + exec()`: Too complex for this use case
- `pipe() + fork() + exec()`: Same as popen() internally

popen() is perfect because:
- Simple API
- Captures stdout
- Handles fork/exec internally
- Returns FILE* for easy reading

### Why We Parse Suggestions

```c
Input ast = psInput(suggestion);  // Parse AI output
visitInput(ast, ctx);              // Execute normally
```

Alternatives considered:
- `system(suggestion)`: DANGEROUS, bypasses validation
- Direct execution: Bypasses BNFC, loses safety

Using BNFC parser ensures:
- Syntax validation
- Same execution path as manual commands
- Proper error handling
- Visitor pattern applies

## Testing Strategy

### Unit Tests (Standalone)

1. **main.c JSON output**
```bash
./picobox --commands-json | python3 -m json.tool
```

2. **Python script**
```bash
python3 mysh_llm.py "test query"
```

### Integration Tests (Shell)

1. **@ detection**
```bash
echo -e "@list files\nn\nexit" | ./picobox
```

2. **Execution**
```bash
echo -e "@list files\ny\nexit" | ./picobox
```

### Regression Tests

1. **Normal commands**
```bash
echo -e "ls\nexit" | ./picobox
```

2. **AICmd**
```bash
echo -e "AI test\nexit" | ./picobox
```

## Common Pitfalls

### Pitfall 1: Forgetting to Clear Input Buffer

```c
// WRONG
scanf(" %c", &answer);
// Input buffer still has newline!

// CORRECT
scanf(" %c", &answer);
while ((c = getchar()) != '\n' && c != EOF);  // Clear buffer
```

### Pitfall 2: Not Escaping Query

```c
// WRONG
snprintf(cmd, sizeof(cmd), "python3 mysh_llm.py %s", query);
// If query contains spaces or quotes, this breaks

// CORRECT
snprintf(cmd, sizeof(cmd), "python3 mysh_llm.py \"%s\"", query);
// Still not perfect (query could contain quotes)
```

### Pitfall 3: Not Checking popen() Return

```c
// WRONG
FILE *fp = popen(cmd, "r");
fgets(suggestion, sizeof(suggestion), fp);  // Crash if fp is NULL!

// CORRECT
FILE *fp = popen(cmd, "r");
if (!fp) {
    perror("popen");
    return;
}
```

### Pitfall 4: Not Freeing AST

```c
// WRONG
Input ast = psInput(suggestion);
visitInput(ast, ctx);
// Memory leak!

// CORRECT
Input ast = psInput(suggestion);
visitInput(ast, ctx);
free_Input(ast);  // Free AST
```

## Debugging

### Enable Debug Output

```bash
export MYSH_LLM_DEBUG=1
./picobox
$ @test
[mysh_llm] Running catalog command: ./picobox --commands-json
[mysh_llm] Heuristic suggestion: ls
...
```

### Trace Execution

```c
// Add to handle_llm_query()
fprintf(stderr, "DEBUG: Query: %s\n", query);
fprintf(stderr, "DEBUG: Command: %s\n", cmd);
fprintf(stderr, "DEBUG: Suggestion: %s\n", suggestion);
```

### GDB Breakpoints

```bash
gdb ./picobox
(gdb) break handle_llm_query
(gdb) run
$ @test
(gdb) print query
(gdb) print suggestion
(gdb) continue
```

## Extending

### Adding Options to JSON

Currently options array is empty. To populate:

1. Access command's argtable3 structure
2. Iterate through arg_* elements
3. Extract short/long names, help text
4. Add to JSON output

```c
// Pseudo-code
if (spec && spec->argtable) {
    void **table = spec->argtable;
    for (int j = 0; table[j] != NULL; j++) {
        // Determine type (arg_lit, arg_str, etc.)
        // Extract short/long names
        // Extract help text
        // Add to JSON
    }
}
```

### Supporting Multiple Suggestions

1. Modify mysh_llm.py to return top 3 commands
2. Parse multiple lines in shell
3. Display numbered list
4. Let user pick by number

### Adding Local LLM Support

1. Modify `call_llm()` in mysh_llm.py
2. Add Ollama API call
3. Set environment variable to choose backend

```python
backend = os.environ.get("MYSH_LLM_BACKEND", "openai")
if backend == "ollama":
    return call_ollama(prompt)
else:
    return call_openai(prompt)
```

## Performance Considerations

### Catalog Caching

Currently, Python script calls `--commands-json` every time. Could cache:

```python
_catalog_cache = None
_catalog_cache_time = 0

def load_command_catalog():
    global _catalog_cache, _catalog_cache_time
    now = time.time()
    if _catalog_cache and now - _catalog_cache_time < 60:
        return _catalog_cache
    # ... load catalog ...
    _catalog_cache = result
    _catalog_cache_time = now
    return result
```

### Async API Calls

Currently blocks on OpenAI API. Could make async:

```python
import asyncio
async def call_llm_async(prompt):
    # Async OpenAI call
```

But this adds complexity for minimal benefit in a shell.

### Parallelization

Could score commands in parallel:

```python
from multiprocessing import Pool
with Pool() as pool:
    scores = pool.starmap(score_command, [(query, cmd) for cmd in catalog])
```

But catalog is small (<100 commands), not worth complexity.

## Security Considerations

### Never Execute Directly

```c
// NEVER DO THIS
system(suggestion);  // DANGEROUS!

// ALWAYS DO THIS
Input ast = psInput(suggestion);  // Validate via parser
if (ast) visitInput(ast, ctx);    // Execute safely
```

### Always Require Confirmation

```c
// User must explicitly approve
printf("Run this command? (y/n): ");
scanf(" %c", &answer);
if (answer != 'y' && answer != 'Y') {
    return;  // Don't execute
}
```

### Sanitize Query

Future improvement: Escape special characters in query before passing to shell.

```c
// TODO: Proper escaping
char *escape_for_shell(const char *str) {
    // Escape: $ ` \ " ' ; & | < > ( ) { } [ ] * ? ~
}
```

### Limit Suggestion Length

```c
#define MAX_SUGGESTION_LENGTH 1024
char suggestion[MAX_SUGGESTION_LENGTH];
```

Prevents buffer overflow if Python script goes crazy.

## Maintenance

### When Adding New Commands

1. Register in `init_commands()`
2. `--commands-json` automatically includes it
3. No changes needed in Python script
4. RAG will automatically score it

### When Changing Grammar

1. If grammar changes, AICmd continues to work
2. @ detection is independent of grammar
3. Both systems coexist peacefully

### When Updating Dependencies

1. OpenAI Python package: `pip install --upgrade openai`
2. Test both LLM and fallback modes
3. Check for API changes in call_llm()

## FAQ

**Q: Why not parse @ in the grammar?**

A: Would require adding @ to lexer, modifying grammar, handling in visitor. Current approach is simpler and keeps both AI systems independent.

**Q: Why popen() instead of pipe()?**

A: popen() is simpler and handles fork/exec internally. No need for low-level pipe management.

**Q: Why JSON instead of other formats?**

A: JSON is standard, has good library support in Python, human-readable for debugging.

**Q: Why visitor pattern for execution?**

A: Already implemented for normal commands. Reusing ensures consistency and safety.

**Q: Can we remove cmd_ai.c now?**

A: You could, but keeping both shows architectural evolution. Good for educational purposes.
```

#### **6.3: Clean Up Code Comments**

Go through all modified files and ensure:
- Function comments are complete
- Inline comments explain why, not what
- Remove dead code
- Remove TODO comments that are done

```c
// GOOD COMMENT (explains why)
/* We check for @ BEFORE parsing because the grammar
 * doesn't include @ as a valid token. This keeps
 * both AI systems independent. */

// BAD COMMENT (explains what, which is obvious)
/* Check if first character is @ */
if (line[0] == '@') {
```

#### **6.4: Update README**

Add section to main README:

```markdown
## AI Assistant Features

PicoBox includes two AI assistant systems:

### @ Prefix System (Recommended)

Natural language to command translation:

```bash
$ @show me all .c files
ðŸ’¡ AI Suggested Command:
   find . -name "*.c"
Run this command? (y/n): y
```

Features:
- RAG (Retrieval-Augmented Generation)
- User confirmation required
- Works with or without OpenAI API key
- See [AI_USER_GUIDE.md](AI_USER_GUIDE.md)

### AI Command (Legacy)

Direct AI chat for help:

```bash
$ AI how do I list files
âœ¨ You can use the 'ls' command...
```

Setup:
```bash
export OPENAI_API_KEY='your-key'
export MYSH_PATH=./picobox
```

For full documentation, see [AI_USER_GUIDE.md](AI_USER_GUIDE.md) and [AI_DEVELOPER_GUIDE.md](AI_DEVELOPER_GUIDE.md).
```

#### **6.5: Create Changelog**

**File**: `CHANGELOG.md`

```markdown
# Changelog

## [2.0.0] - 2024-12-03

### Added - AI Integration

- **@ Prefix AI Assistant**: Natural language to command translation
  - Syntax: `@<query>` (e.g., `@show all files`)
  - Uses mysh_llm.py with RAG and OpenAI integration
  - Fallback mode works without API key
  - User confirmation required for safety

- **Command Catalog Export**: `picobox --commands-json`
  - Exports all registered commands in JSON format
  - Used by AI assistant for RAG
  - Enables external tools to query available commands

- **Documentation**:
  - [AI_USER_GUIDE.md](AI_USER_GUIDE.md) - User documentation
  - [AI_DEVELOPER_GUIDE.md](AI_DEVELOPER_GUIDE.md) - Developer guide
  - [test_ai_integration.sh](test_ai_integration.sh) - Test suite

### Changed

- Updated help message to document both AI systems
- Updated shell banner with AI feature info
- Enhanced error messages for AI failures

### Technical Details

- Added `print_commands_json()` to main.c
- Added `handle_llm_query()` to shell_bnfc.c
- @ detection happens before BNFC parsing
- AI suggestions executed via normal BNFC pipeline
- Both AI systems (@ and AICmd) coexist independently

### Testing

- 15+ manual test cases
- Automated test suite (test_ai_integration.sh)
- Regression testing confirms no breakage
- Memory leak testing with valgrind

### Dependencies

- Python 3.7+ (for mysh_llm.py)
- openai package (pip install openai)
- Optional: OPENAI_API_KEY environment variable

## [1.0.0] - Previous

- All previous features...
```

**Git Commit**:
```bash
git add AI_USER_GUIDE.md AI_DEVELOPER_GUIDE.md CHANGELOG.md README.md
git commit -m "Add comprehensive documentation for AI integration

- User guide with examples and troubleshooting
- Developer guide with architecture and implementation details
- Updated README with AI features
- Added changelog entry
"
```

---

### **PHASE 7: Final Verification & Release**
**Time Estimate**: 1 hour

Final checks before considering the implementation complete.

#### **7.1: Run Full Test Suite**

```bash
# Run automated tests
./test_ai_integration.sh

# Manual verification
./picobox

# Test @ queries
$ @list files
$ @find C files
$ @count lines
$ exit

# Test normal commands
./picobox
$ ls
$ cat file.txt
$ echo test | grep test
$ exit

# Test legacy AI
./picobox
$ AI how do I list files
$ exit
```

**Expected**: All tests pass, no errors.

#### **7.2: Performance Check**

```bash
# Time various operations
time ./picobox --commands-json > /dev/null

time (echo -e "@list files\nn\nexit" | ./picobox)

time (echo -e "ls\nexit" | ./picobox)
```

**Expected**: 
- `--commands-json`: <100ms
- @ query: <5 seconds (network dependent)
- Normal command: <100ms

#### **7.3: Memory Leak Check**

```bash
valgrind --leak-check=full --show-leak-kinds=all ./picobox << 'EOF'
@list files
n
ls
echo test
exit
EOF
```

**Expected**: No memory leaks reported.

#### **7.4: Create Release Tag**

```bash
# Ensure all changes committed
git status

# Create annotated tag
git tag -a v2.0.0 -m "Release v2.0.0: AI Integration

Features:
- @ prefix AI assistant with RAG
- Command catalog export (--commands-json)
- mysh_llm.py integration
- Comprehensive documentation
- Full test suite

Both AI systems (@ and AICmd) work independently.
"

# View tag
git show v2.0.0

# Push tag (if using remote)
git push origin v2.0.0
```

#### **7.5: Create Distribution Package**

```bash
# Create tarball
tar -czf picobox-v2.0.0.tar.gz \
    *.c *.h \
    mysh_llm.py \
    Makefile \
    README.md \
    AI_USER_GUIDE.md \
    AI_DEVELOPER_GUIDE.md \
    CHANGELOG.md \
    test_ai_integration.sh \
    --exclude="*.o" \
    --exclude="picobox"

# Verify contents
tar -tzf picobox-v2.0.0.tar.gz | head -20

# Test extraction
mkdir test_extract
cd test_extract
tar -xzf ../picobox-v2.0.0.tar.gz
make
./test_ai_integration.sh
cd ..
rm -rf test_extract
```

#### **7.6: Write Release Notes**

**File**: `RELEASE_NOTES_v2.0.0.md`

```markdown
# PicoBox Shell v2.0.0 Release Notes

## What's New

### ðŸ¤– AI Assistant with @ Prefix

Transform natural language into shell commands:

```bash
$ @show me all .c files modified today
ðŸ’¡ AI Suggested Command:
   find . -name "*.c" -mtime 0
Run this command? (y/n):
```

### Key Features

- **RAG Integration**: AI only suggests existing commands
- **Safe Execution**: User confirmation + BNFC validation
- **Fallback Mode**: Works without OpenAI API key
- **Dual AI Systems**: @ prefix (new) + AI command (legacy)

## Installation

### Requirements

- GCC/Clang compiler
- Make
- Python 3.7+
- OpenAI Python package (optional)

### Quick Setup

```bash
# Extract
tar -xzf picobox-v2.0.0.tar.gz
cd picobox-v2.0.0

# Install Python package
pip install openai

# Set API key (optional)
export OPENAI_API_KEY='your-key'

# Build
make

# Test
./test_ai_integration.sh

# Run
./picobox
```

## Documentation

- **[AI_USER_GUIDE.md](AI_USER_GUIDE.md)**: How to use AI features
- **[AI_DEVELOPER_GUIDE.md](AI_DEVELOPER_GUIDE.md)**: Implementation details
- **[CHANGELOG.md](CHANGELOG.md)**: Complete change history

## Upgrade Guide

If upgrading from v1.0:

1. No breaking changes to existing features
2. Add mysh_llm.py to your directory
3. Install openai package
4. Set OPENAI_API_KEY (optional)
5. Recompile

## Examples

### File Operations
```bash
@list all files
@find python files
@show hidden files
```

### Searching
```bash
@search for "error" in logs
@find files modified today
```

### System Info
```bash
@show disk usage
@check free space
```

## What's Next

Future enhancements:
- Multiple suggestions (choose from top 3)
- Local LLM support (Ollama)
- Better scoring algorithm
- Context awareness

## Known Issues

- Query escaping needs improvement for special characters
- Options array in JSON catalog not yet populated
- Large catalog (100+ commands) slows down scoring

## Credits

- RAG implementation based on course materials
- mysh_llm.py from Professor's reference implementation
- Integration designed for educational purposes

## License

Educational project for CS course.

## Support

For issues, questions, or contributions, see documentation or contact maintainers.
```

#### **7.7: Final Checklist**

Before considering the implementation complete, verify:

- [ ] Code compiles without warnings
- [ ] All tests pass
- [ ] No memory leaks
- [ ] Documentation is complete
- [ ] Both AI systems work
- [ ] Normal commands work (regression)
- [ ] --commands-json produces valid JSON
- [ ] mysh_llm.py works standalone
- [ ] @ detection works in shell
- [ ] User confirmation works
- [ ] Error handling is robust
- [ ] Help message is updated
- [ ] README is updated
- [ ] Changelog is complete
- [ ] Release notes written
- [ ] Git tags created
- [ ] Distribution package created

**Git Final Commit**:
```bash
git add RELEASE_NOTES_v2.0.0.md
git commit -m "Prepare v2.0.0 release

- Final testing complete
- All documentation ready
- Distribution package created
- Release notes finalized

Ready for deployment.
"
```

---

## ðŸŽ‰ **COMPLETION CRITERIA**

The implementation is **COMPLETE** when:

âœ… **Functionality**:
- `picobox --commands-json` outputs valid JSON
- `mysh_llm.py` works standalone
- `@list files` in shell shows suggestion
- User can confirm/cancel suggestions
- Confirmed commands execute correctly
- Normal commands still work
- Legacy `AI` command still works

âœ… **Quality**:
- No compiler warnings
- No memory leaks (valgrind clean)
- No crashes or segfaults
- Error messages are helpful
- Code is well-commented

âœ… **Testing**:
- Automated test suite passes
- Manual testing complete
- Edge cases handled
- Regression testing passed

âœ… **Documentation**:
- User guide complete
- Developer guide complete
- README updated
- Changelog updated
- Release notes written

âœ… **Release**:
- Code committed to git
- Version tagged
- Distribution package created
- Ready for deployment

---

## ðŸ“ **POST-IMPLEMENTATION NOTES**

### Lessons Learned

1. **Separation of Concerns**: Keeping AI in Python and shell in C was the right choice
2. **Testing Early**: Standalone testing of each component saved debugging time
3. **Error Handling**: Comprehensive error handling prevents frustration
4. **Documentation**: Writing docs during development kept them accurate

### Future Maintenance

1. **When adding commands**: They automatically appear in AI assistant
2. **When updating OpenAI API**: Only modify mysh_llm.py
3. **When fixing bugs**: Check both AI systems independently
4. **When optimizing**: Profile Python script first (likely bottleneck)

### Technical Debt

Items to address in future versions:
1. Populate options array in JSON catalog
2. Improve query escaping for special characters
3. Add catalog caching for performance
4. Support multiple suggestions
5. Add local LLM support

---

## ðŸŽ¯ **SUCCESS METRICS**

After implementation, you should be able to:

1. âœ… Type `@list files` and get a working suggestion
2. âœ… Use the shell normally without noticing AI integration
3. âœ… Run tests and see all passing
4. âœ… Explain the architecture to someone else
5. âœ… Modify the Python script without touching C code
6. âœ… Add new commands without updating AI code

**Congratulations! You've successfully integrated a modern AI assistant into your shell using industry-standard practices!** ðŸš€